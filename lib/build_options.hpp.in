#ifndef BUILD_OPTIONS_HPP
#define BUILD_OPTIONS_HPP


#cmakedefine01 FLOAT_PRECISION
enum class Platform: int {CPU = 0, GPU = 1};

#include "stdint.h"
#include <functional>
#include <chrono>
using luint = uint64_t;
using lint  = int64_t;
constexpr int BLOCK_SIZE   = 128;
constexpr int BLOCK_SIZE2D = 16;
constexpr int BLOCK_SIZE3D = 4;
constexpr int MAX_ITER     = 1000;
// Precision preprocessing
#if FLOAT_PRECISION
using real = float;
constexpr real tol_scale = 1e-6;
#else
using real = double;
constexpr real tol_scale = 1e-12;
#endif 

// NVIDIA seems to like to stencil better in 
// column major order for some reason...hmmmm
// #if defined(__HIP_PLATFORM_NVIDIA__)
// #define CYTHON_COL_MAJOR 1 
// constexpr bool col_maj = true;
// #else 
#define CYTHON_COL_MAJOR 0
constexpr bool col_maj = false;
// #endif 

#if defined(__NVCC__) || defined(__HCC__) || (defined(__clang__) && defined(__HIP__))
#define GPU_CODE 1
constexpr Platform BuildPlatform = Platform::GPU;
// typedef float real;

#define GPU_DEV                        __device__
#define GPU_DEV_INLINE                 __device__ inline
#define GPU_LAUNCHABLE                 __global__
#define GPU_LAMBDA                     __device__
#define GPU_CALLABLE                   __host__ __device__
#define GPU_CALLABLE_INLINE            __host__ __device__ inline
#define GPU_CALLABLE_MEMBER            __host__ __device__
#define GPU_CALLABLE_INLINE_MEMBER     __host__ __device__ inline
#define EXTERN_SHARED                  extern __shared__
#define STATIC_SHARED                  static __shared__
#define GPU_CAPTURE                    [=, *this]

#if defined(__NVCC__) && !defined(__HIP__)
#include <cuda_runtime.h>
#define CUDA_CODE 1
using simbiStream_t = cudaStream_t;
constexpr int WARP_SIZE    = 32;
#define anyGpuMalloc                cudaMalloc
#define anyGpuMallocManaged         cudaMallocManaged
#define anyGpuMemcpy                cudaMemcpy
#define anyGpuFree                  cudaFree
#define anyGpuMemset                cudaMemset
#define anyGpuDeviceSynchronize     cudaDeviceSynchronize
#define anyGpuMemcpyHostToDevice    cudaMemcpyHostToDevice
#define anyGpuMemcpyDeviceToDevice  cudaMemcpyDeviceToDevice
#define anyGpuMemcpyDeviceToHost    cudaMemcpyDeviceToHost
#define anyGpuGetErrorString        cudaGetErrorString
#define anyGpuError_t               cudaError_t
#define anyGpuEvent_t               cudaEvent_t 
#define anyGpuEventCreate           cudaEventCreate
#define anyGpuEventRecord           cudaEventRecord 
#define anyGpuEventSynchronize      cudaEventSynchronize 
#define anyGpuEventElapsedTime      cudaEventElapsedTime
#else 
#include "hip/hip_runtime.h"
#define HIP_CODE 1
using simbiStream_t = hipStream_t;
constexpr int WARP_SIZE    = 64;
#define anyGpuMalloc                hipMalloc
#define anyGpuMallocManaged         hipMallocManaged
#define anyGpuMemcpy                hipMemcpy
#define anyGpuFree                  hipFree
#define anyGpuMemset                hipMemset
#define anyGpuMemcpyHostToDevice    hipMemcpyHostToDevice
#define anyGpuMemcpyDeviceToDevice  hipMemcpyDeviceToDevice
#define anyGpuMemcpyDeviceToHost    hipMemcpyDeviceToHost
#define anyGpuDeviceSynchronize     hipDeviceSynchronize
#define anyGpuGetErrorString        hipGetErrorString
#define anyGpuError_t               hipError_t
#define anyGpuEvent_t               hipEvent_t 
#define anyGpuEventCreate           hipEventCreate
#define anyGpuEventRecord           hipEventRecord 
#define anyGpuEventSynchronize      hipEventSynchronize 
#define anyGpuEventElapsedTime      hipEventElapsedTime
#endif
#else
constexpr int WARP_SIZE    = 32;
#define GPU_CODE 0
#define CUDA_CODE 0
#define HIP_CODE 0
#include <cmath>
#include <cstring>
#include <string>
#include <stdint.h>
#include <stdexcept>
constexpr Platform BuildPlatform = Platform::CPU;

#define GPU_DEV                         
#define GPU_LAUNCHABLE                 
#define GPU_LAMBDA                     
#define GPU_CALLABLE               
#define GPU_CALLABLE_INLINE          inline
#define GPU_CALLABLE_MEMBER        
#define GPU_CALLABLE_INLINE_MEMBER   inline
#define GPU_DEV_INLINE               inline 
#define __shared__                   static
#define GPU_SHARED_DYN               extern __shared__
#define GPU_CAPTURE                  [this]
#define STATIC_SHARED                static
// Define a bunch of ghost functions to make the compiler
// happy and avoid a bunch if #ifdefs throughout code
// Don't get too mad at me... I'm a physicist, not a programmer :-)
namespace simbi {
    // struct BuildOptions
    // {
    //     constexpr static bool gpu_on = static_cast<bool>(GPU_CODE);
    // };

    struct u3
    {
        ~u3() = default;
        uint32_t x;
        uint32_t y;
        uint32_t z;

        u3(uint32_t x = 1, uint32_t y = 1, uint32_t z = 1)
        :
        x(x),
        y(y),
        z(z)
        {
            
        }

    };

    using simbiStream_t = int;
    using anyGpuError_t = int;
    using anyGpuEvent_t = std::chrono::high_resolution_clock::time_point;
    enum anyGpuMemcpyType {
        anyGpuMemcpyHostToDevice,
        anyGpuMemcpyDeviceToDevice,
        anyGpuMemcpyDeviceToHost
    };
    using dim3 = u3;
    inline dim3 blockIdx(1, 1, 1); 
    inline dim3 blockDim(1, 1, 1); 
    inline dim3 gridDim(1, 1, 1); 
    inline dim3 threadIdx(1, 1, 1);
    constexpr Platform pyBuild = BuildPlatform;

    inline int anyGpuMallocManaged(void** ptr , size_t size) {
        return 0;
    }

    inline int anyGpuMalloc(void** ptr , size_t size) {
        return 0;
    }

    inline int anyGpuMemset(void* ptr, int val, size_t size){
        return 0;
    }

    template <typename T> inline int anyGpuFree(T * ptr) {
        return 0;
    }

    inline int anyGpuMemcpy( void* dest , const void* src , size_t size, anyGpuMemcpyType tt) {
        return 0;
    }

    inline int anyGpuEventCreate(anyGpuEvent_t *a) {
        return 0;
    }

    inline int anyGpuEventRecord(anyGpuEvent_t a) {
        return 0;
    }

    inline int anyGpuEventSynchronize(anyGpuEvent_t a) {
        return 0;
    }

    inline int anyGpuEventElapsedTime(float *time, anyGpuEvent_t a, anyGpuEvent_t b) {
        return 0;
    }
    inline void __syncthreads() { return;}
    inline anyGpuError_t anyGpuDeviceSynchronize() { return 0;}

    template <typename T>
    inline std::string anyGpuGetErrorString(T) { return std::string("nothing odd here.");}
} // end simbi

using namespace simbi;

#endif

constexpr int inf      = std::numeric_limits<int>::max();
constexpr int dt_inf   = 100000;
// #if FLOAT_PRECISION
// const auto sqrt = sqrtf;
// #else 
// const auto sqrt = static_cast<double(*)(const double)>(std::sqrt);
// #endif



#endif
