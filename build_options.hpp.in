/**
 * ***********************(C) COPYRIGHT 2023 Marcus DuPont**********************
 * @file       build_options.hpp.in
 * @brief      file to configure build mode for various cpu / gpu architectures
 *
 * @note
 * @history:
 *   Version   Date            Author          Modification    Email
 *   V0.8.0    Dec-03-2023     Marcus DuPont                   md4469@nyu.edu
 *
 * @verbatim
 * ==============================================================================
 *
 * ==============================================================================
 * @endverbatim
 * ***********************(C) COPYRIGHT 2023 Marcus DuPont**********************
 */
#ifndef BUILD_OPTIONS_HPP
#define BUILD_OPTIONS_HPP

#mesondefine FLOAT_PRECISION
#mesondefine COLUMN_MAJOR
#mesondefine FOUR_VELOCITY
#mesondefine PROGRESS_BAR
#mesondefine SHARED_MEMORY

#include <atomic>      // for atomic
#include <chrono>      // for high_resolution_clock
#include <cinttypes>   // for uint32_t, int64_t, uint64_t
#include <csignal>     // for size_t
#include <string>      // for allocator, string

/*
 * defines a global namespace for functions and
 * variables scattered throughout the code
 */
namespace global {
    // Flag that detects whether program is run using openmp
    inline bool use_omp = false;

    enum class Platform : int {
        CPU = 0,
        GPU = 1
    };
    enum class Runtime : int {
        CUDA = 0,
        ROCM = 1,
        CPU  = 2
    };
    enum class Velocity : int {
        Beta         = 0,
        FourVelocity = 1
    };

// enum to check the relativistic primitive velocity type (beta, or gamma-beta)
#if FOUR_VELOCITY
    constexpr Velocity VelocityType = Velocity::FourVelocity;
#else
    constexpr Velocity VelocityType = global::Velocity::Beta;
#endif

#if PROGRESS_BAR
    constexpr bool progress_bar_enabled = true;
#else
    constexpr bool progress_bar_enabled = false;
#endif

#if DEBUG
    constexpr bool debug_mode = true;
#else
    constexpr bool debug_mode = false;
#endif

    // max iterations in newton-raphson loop
    const int MAX_ITER = 1000;
}   // namespace global

using luint = uint64_t;
using lint  = int64_t;

//========================= FLOAT PRECISION CHECK
#if FLOAT_PRECISION
#if defined(GPU_PLATFORM_AMD)
using atomic_cast = unsigned int;
#else
using atomic_cast = int;
#endif
#define __int_as_real __int_as_float
#define __real_as_int __float_as_int
using real = float;

namespace global {
    // newton-raphson tolerance scale
    constexpr real tol_scale = 1e-6;
}   // namespace global
#else
#if defined(GPU_PLATFORM_AMD)
using atomic_cast = unsigned long long;
#else
using atomic_cast = long long;
#endif
#define __int_as_real __longlong_as_double
#define __real_as_int __double_as_longlong
using real = double;

namespace global {
    // newton-raphson tolerance scale
    constexpr real tol_scale = 1e-12;
}   // namespace global
#endif

namespace global {
//======================== COLUMN MAJOR CHECK
#if COLUMN_MAJOR
    // column major flag
    constexpr bool col_maj = true;
#else
    // column major flag
    constexpr bool col_maj = false;
#endif

//======================== Managed Memory Check
#ifdef MANAGED_MEMORY
    // unified memory flag
    constexpr bool managed_memory = true;
#else
    // unified memory flag
    constexpr bool managed_memory = false;
#endif
}   // namespace global

//=========================== RUNTIME CHECK
#if GPU_CODE
using sig_bool = volatile bool;
#define LAUNCH_ASYNC(kernel_name, gridsize, blocksize, ...)                    \
    kernel_name<<<((gridsize), (blocksize))>>>(__VA_ARGS__);

namespace global {
#if SHARED_MEMORY
#define GPU_SHARED __device__
    // shorthand flag for using gpu shared memory
    constexpr bool on_sm = true;
#else
#define GPU_SHARED __device__ const
    // shorthand flag for using gpu shared memory
    constexpr bool on_sm = false;
#endif
    constexpr Platform BuildPlatform = Platform::GPU;
}   // namespace global

#define GPU_DEV                    __device__
#define GPU_DEV_INLINE             __device__ inline
#define GPU_LAUNCHABLE             __global__
#define GPU_LAMBDA                 __device__
#define GPU_CALLABLE               __host__ __device__
#define GPU_CALLABLE_INLINE        __host__ __device__ inline
#define GPU_CALLABLE_MEMBER        __host__ __device__
#define GPU_CALLABLE_INLINE_MEMBER __host__ __device__ inline
#define GPU_EXTERN_SHARED          extern __shared__

#if GPU_PLATFORM_NVIDIA
#include <cuda_runtime.h>
#define CUDA_CODE 1

namespace global {
    constexpr int WARP_SIZE = 32;
}   // namespace global

template <typename T>
constexpr auto devMalloc(T** devPtr, size_t size)
{
    return cudaMalloc(devPtr, size);
}

template <typename T>
constexpr auto devMallocManaged(T** devPtr, size_t size)
{
    return cudaMallocManaged(devPtr, size);
}

inline auto devEventCreate(cudaEvent_t* stamp)
{
    return cudaEventCreate(stamp);
};

inline auto devEventRecord(cudaEvent_t stamp)
{
    return cudaEventRecord(stamp);
};

constexpr auto devMemcpy               = cudaMemcpy;
constexpr auto devFree                 = cudaFree;
constexpr auto devMemset               = cudaMemset;
constexpr auto devDeviceSynchronize    = cudaDeviceSynchronize;
constexpr auto devMemcpyHostToDevice   = cudaMemcpyHostToDevice;
constexpr auto devMemcpyDeviceToDevice = cudaMemcpyDeviceToDevice;
constexpr auto devMemcpyDeviceToHost   = cudaMemcpyDeviceToHost;
constexpr auto devGetErrorString       = cudaGetErrorString;
constexpr auto devEventDestroy         = cudaEventDestroy;
constexpr auto devEventSynchronize     = cudaEventSynchronize;
constexpr auto devEventElapsedTime     = cudaEventElapsedTime;
constexpr auto devGetDeviceProperties  = cudaGetDeviceProperties;
constexpr auto devGetDeviceCount       = cudaGetDeviceCount;
using devProp_t                        = cudaDeviceProp;
using devError_t                       = cudaError_t;
using devEvent_t                       = cudaEvent_t;
using simbiStream_t                    = cudaStream_t;
#elif GPU_PLATFORM_AMD
#include "hip/hip_runtime.h"
#define HIP_CODE 1

namespace global {
    constexpr int WARP_SIZE = 64;
}   // namespace global

template <typename T>
constexpr auto devMalloc(T** devPtr, size_t size)
{
    return hipMalloc(devPtr, size);
}

template <typename T>
constexpr auto devMallocManaged(T** devPtr, size_t size)
{
    return hipMallocManaged(devPtr, size);
}

inline auto devEventCreate(hipEvent_t* stamp) { return hipEventCreate(stamp); };

inline auto devEventRecord(hipEvent_t stamp) { return hipEventRecord(stamp); };

constexpr auto devMemcpy               = hipMemcpy;
constexpr auto devFree                 = hipFree;
constexpr auto devMemset               = hipMemset;
constexpr auto devDeviceSynchronize    = hipDeviceSynchronize;
constexpr auto devMemcpyHostToDevice   = hipMemcpyHostToDevice;
constexpr auto devMemcpyDeviceToDevice = hipMemcpyDeviceToDevice;
constexpr auto devMemcpyDeviceToHost   = hipMemcpyDeviceToHost;
constexpr auto devGetErrorString       = hipGetErrorString;
constexpr auto devEventDestroy         = hipEventDestroy;
constexpr auto devEventSynchronize     = hipEventSynchronize;
constexpr auto devEventElapsedTime     = hipEventElapsedTime;
constexpr auto devGetDeviceProperties  = hipGetDeviceProperties;
constexpr auto devGetDeviceCount       = hipGetDeviceCount;
using devProp_t                        = hipDeviceProp_t;
using devError_t                       = hipError_t;
using devEvent_t                       = hipEvent_t;
using simbiStream_t                    = hipStream_t;
#endif
#else
using sig_bool = std::atomic<bool>;
#define LAUNCH_ASYNC(kernel_name, gridsize, blocksize, ...)                    \
    kernel_name(__VA_ARGS__);

namespace global {
    constexpr auto BuildPlatform = Platform::CPU;
    constexpr int WARP_SIZE      = 32;
    // shorthand flag for using gpu shared memory
    constexpr bool on_sm = false;
}   // namespace global

#define CUDA_CODE 0
#define HIP_CODE  0

#define GPU_DEV
#define GPU_LAUNCHABLE
#define GPU_LAMBDA
#define GPU_CALLABLE
#define GPU_CALLABLE_INLINE inline
#define GPU_CALLABLE_MEMBER
#define GPU_CALLABLE_INLINE_MEMBER inline
#define GPU_DEV_INLINE             inline
#define __shared__                 static
#define GPU_SHARED                 const
#define GPU_EXTERN_SHARED

// Alias data types on host
namespace simbi {
    struct dim3 {
        ~dim3() = default;
        dim3()  = default;
        uint32_t x;
        uint32_t y;
        uint32_t z;

        dim3(uint32_t x, uint32_t y, uint32_t z) : x(x), y(y), z(z) {}

        dim3(uint32_t x, uint32_t y) : x(x), y(y), z(1) {}

        dim3(uint32_t x) : x(x), y(1), z(1) {}
    };

    using simbiStream_t = int;
    using devError_t    = int;
    using devProp_t     = int;
    using devEvent_t    = std::chrono::high_resolution_clock::time_point;

    inline dim3 blockIdx(1, 1, 1);
    inline dim3 blockDim(1, 1, 1);
    inline dim3 gridDim(1, 1, 1);
    inline dim3 threadIdx(1, 1, 1);
}   // namespace simbi
#endif

namespace global {
    // shorthand flag for gpu compilation check
    constexpr bool on_gpu = BuildPlatform == Platform::GPU;
}   // namespace global
#endif
